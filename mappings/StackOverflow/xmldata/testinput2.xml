<?xml version="1.0" encoding="utf-8"?><rss xmlns:a10="http://www.w3.org/2005/Atom" version="2.0"><channel xmlns:os="http://a9.com/-/spec/opensearch/1.1/"><title>Emplois de  correspondant à ""Data Science"" - Stack Overflow Careers</title>
        <link>http://careers.stackoverflow.com/jobs</link>
        <description>Emplois de  correspondant à ""Data Science"" - Stack Overflow Careers</description><os:totalResults>2</os:totalResults>
        <item><guid isPermaLink="true">http://careers.stackoverflow.com/jobs/55843/data-analytics-engineer-sharethrough</guid><link>http://careers.stackoverflow.com/jobs/55843/data-analytics-engineer-sharethrough</link> <a10:author><a10:name>Sharethrough</a10:name></a10:author><category>apache-spark</category><category>amazon-redshift</category><category>sql</category><category>python</category><category>data-warehouse</category> <title>Data Analytics Engineer at Sharethrough (San Francisco, CA)</title><description>&lt;p&gt;&lt;span&gt;Sharethrough is looking for engineers interested in building data products and infrastructure to power our business and provide insight to our customers. &amp;nbsp;You'll be taking the lead on the design and implementation of a data warehousing infrastructure used by our product, engineering and operational teams.&lt;/span&gt;&lt;/p&gt;&lt;br /&gt;&lt;p&gt;&lt;span&gt;What You'll Be Doing:&lt;/span&gt;&lt;/p&gt;&lt;br /&gt;&lt;ul&gt;&lt;br /&gt;&lt;li&gt;&lt;span&gt;Greenfield architecture and construction of a modern data warehouse&lt;/span&gt;&lt;/li&gt;&lt;br /&gt;&lt;li&gt;&lt;span&gt;Working with new technologies such as Apache Spark and Amazon Redshift&lt;/span&gt;&lt;/li&gt;&lt;br /&gt;&lt;li&gt;&lt;span&gt;Deriving insight from large quantities of data, starting with our 500GB/day performance pipeline&lt;/span&gt;&lt;/li&gt;&lt;br /&gt;&lt;li&gt;&lt;span&gt;Collaborating with data science and business intelligence teams on visualization and data wrangling platforms such as Looker&lt;/span&gt;&lt;/li&gt;&lt;br /&gt;&lt;/ul&gt;&lt;br /&gt;&lt;p&gt;&lt;span&gt;Let&amp;rsquo;s talk if...&lt;/span&gt;&lt;/p&gt;&lt;br /&gt;&lt;ul&gt;&lt;br /&gt;&lt;li&gt;&lt;span&gt;You&amp;rsquo;ve got experience with SQL, ETL, python/shell scripting, and MPP Data Warehousing&lt;/span&gt;&lt;/li&gt;&lt;br /&gt;&lt;li&gt;&lt;span&gt;You&amp;rsquo;ve worked on or are interested in data integrity governance and semantic layer design&lt;/span&gt;&lt;/li&gt;&lt;br /&gt;&lt;li&gt;&lt;span&gt;You possess an intense curiosity about data and a strong commitment to practical problem solving&lt;/span&gt;&lt;/li&gt;&lt;br /&gt;&lt;/ul&gt;</description><pubDate>Wed, 05 Aug 2015 21:08:27 Z</pubDate><a10:updated>2015-08-05T21:08:27Z</a10:updated><location>San Francisco, CA</location></item>
<item>
    <guid isPermaLink="true">http://careers.stackoverflow.com/jobs/92579/lead-software-engineer-for-the-nih-nci-genomic-the-university-of-chicago</guid>
    <link>http://careers.stackoverflow.com/jobs/92579/lead-software-engineer-for-the-nih-nci-genomic-the-university-of-chicago</link>
    <a10:author><a10:name>The University of Chicago, Center for Data Intensive Science</a10:name></a10:author>
    <category>cloud</category><category>python</category><category>bigdata</category><category>bioinformatics</category><category>hpc</category><title>Lead Software Engineer for the NIH/NCI Genomic Data Commons Project at The University of Chicago, Center for Data Intensive Science (Chicago, IL)</title>
    <description>&lt;p&gt;The&amp;nbsp;Center for Data Intensive Science (CDIS) is looking for a Lead Software Engineer for the National Cancer Institute (NCI) &lt;a href="http://sciencelife.uchospitals.edu/2014/12/02/transforming-cancer-research-the-genomic-data-commons/" rel="nofollow" rel="nofollow" rel="nofollow" rel="nofollow" rel="nofollow" rel="nofollow" rel="nofollow"&gt;Genomic Data Commons&lt;/a&gt; (GDC) project. Alongside our team of experts, the Lead Software Engineer will develop the scalable and interoperable software stack for the GDC, supporting upwards of 5 petabytes of centralized and harmonized cancer genomic data.&lt;/p&gt;&lt;br /&gt;&lt;p&gt;The GDC will provide a open source, scalable, modern informatics framework that uses community standards to make raw and processed genomic data broadly accessible. The GDC will harmonize and centralize existing petabyte-scale cancer genomics datasets through cutting edge approaches to data storage and analysis similar to what is used by successful companies. The GDC will eliminate a major chokepoint, streamlining access to data for researchers regardless of their institution's size or budget, effectively democratizing access to the material. It will also enable previously infeasible collaborative efforts between scientists. &lt;br&gt;The GDC serves as a key step toward the development of precision medicine, targeted treatments that are tailored to individual patients. Once fully developed, it will provide an interactive system for researchers and clinicians to upload genomics data and use it to identify the molecular subtype of cancer and potential therapeutic targets. Genetic data will be linked to extensive clinical information from patients and their response to treatment.&lt;/p&gt;&lt;br /&gt;&lt;p&gt;The Lead Software Engineer in the Center for Data Intensive Science manages all aspects of programming projects, including requirements, design, implementation, deployment/delivery, and support. Leads team efforts and oversees the work of other software engineers. Provides technical oversight and develops standards, guidelines, and processes for applications. Reviews the design and code development of key architectural components. Contributes to decisions on project and infrastructure needs, including the evaluation of server technologies, languages, platforms, and frameworks. Develops timelines, technical diagrams, project plans, and resources allocation in an agile methodology. Works with cloud computing infrastructures including OpenStack, Amazon AWS and Google Cloud to design, develop, maintain, and evaluate software applications to meet business and technical requirements. Works in Linux-based systems primarily with Python and C/C++, with the ability to work with other programming languages as the need arises. Oversees code testing and ensures appropriate standards are met. Works with users, collaborators, and technical staff to resolve problems and respond to feedback regarding potential improvements and enhancements. Ensures appropriate documentation. Serves as a liaison with internal and external collaborators on multiple research projects.&lt;/p&gt;&lt;br /&gt;&lt;p&gt;Research includes the full stack from systems to algorithms to user interfaces. Research projects span management, sharing, and provenance of large data sets; resource allocation and scheduling for cloud computing, large scale pipelining of next-generation sequence analysis, transfer programs/protocols for high-speed networks and resource visualization. &lt;br&gt;Perform other duties as assigned. &lt;br&gt;&lt;br&gt;&lt;em&gt;This position is grant supported and longevity of the position is dependent upon future funding. &amp;nbsp;&lt;/em&gt;&lt;/p&gt;</description><pubDate>Sat, 08 Aug 2015 15:08:27 Z</pubDate><a10:updated>2015-08-08T15:08:27Z</a10:updated>
<location>Chicago, IL</location></item>
</channel></rss>

